{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67e9b1c7cdfc1ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e475e3d015d0dc",
   "metadata": {},
   "source": [
    "## Creación de un simple ChatBot que interactúa con llama 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee809484ba7879e",
   "metadata": {},
   "source": [
    "### 1. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44816349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.9\n",
      "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core==0.3.21\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-ollama==0.2.0\n",
      "  Downloading langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain==0.3.9)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.9)\n",
      "  Downloading SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.9)\n",
      "  Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.9)\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.9)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain==0.3.9)\n",
      "  Downloading numpy-2.2.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain==0.3.9)\n",
      "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting requests<3,>=2 (from langchain==0.3.9)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain==0.3.9)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.21)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\l00447979\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core==0.3.21) (24.2)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core==0.3.21)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting ollama<1,>=0.3.0 (from langchain-ollama==0.2.0)\n",
      "  Downloading ollama-0.4.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.3.21)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.9)\n",
      "  Downloading langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading orjson-3.10.14-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.9)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.9)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain==0.3.9)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain==0.3.9)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain==0.3.9)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain==0.3.9)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.3.9)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting sniffio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "Downloading langchain_ollama-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading numpy-2.2.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 9.7/12.6 MB 46.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 39.5 MB/s eta 0:00:00\n",
      "Downloading ollama-0.4.6-py3-none-any.whl (13 kB)\n",
      "Downloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 27.4 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 39.1 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.14-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, sniffio, PyYAML, propcache, orjson, numpy, multidict, jsonpointer, idna, h11, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, pydantic, httpx, aiohttp, ollama, langsmith, langchain-core, langchain-text-splitters, langchain-ollama, langchain\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.37 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 attrs-24.3.0 certifi-2024.12.14 charset-normalizer-3.4.1 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.9 langchain-core-0.3.21 langchain-ollama-0.2.0 langchain-text-splitters-0.3.2 langsmith-0.1.147 multidict-6.1.0 numpy-2.2.1 ollama-0.4.6 orjson-3.10.14 propcache-0.2.1 pydantic-2.10.5 pydantic-core-2.27.2 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 typing-extensions-4.12.2 urllib3-2.3.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\L00447979\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\L00447979\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\L00447979\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script langsmith.exe is installed in 'c:\\Users\\L00447979\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script langchain-server.exe is installed in 'c:\\Users\\L00447979\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.3.9 langchain-core==0.3.21 langchain-ollama==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d2707c728a2d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:50:56.686095Z",
     "start_time": "2024-11-21T19:50:56.060193Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf26fb11c3b0d",
   "metadata": {},
   "source": [
    "## 2. Large language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab209c5e57c5d3",
   "metadata": {},
   "source": [
    "Hay diferentes modelos que se pueden usar. La mayoría necesita un \"API KEY\":\n",
    "\n",
    "ChatOpenAI, ChatAnthropic, ChatVertexAI, ChatCohere, ChatNVIDIA, ChatGroq, ChatMistralAI\n",
    "\n",
    "Existen otros modelos en la plataforma HUGGINGFACE.\n",
    "\n",
    "Para la mayoría de los modelos hay que definir una variable de entorno:\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "import getpass\n",
    "\n",
    "import os\n",
    "\n",
    "export OPENAI_API_KEY=\"...\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "Usando Ollama en local no es necesario definir variables de entorno. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:51:29.667040Z",
     "start_time": "2024-11-21T19:51:29.646351Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_llm = 'llama3'\n",
    "llm = ChatOllama(model=local_llm, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca09143b4658d2",
   "metadata": {},
   "source": [
    "Algunos de los parámetros más importantes que se deben/pueden especificar:\n",
    "\n",
    "-**model**: el nombre del modelo específico que se quiere usar (por ejemplo, para ChatOpenAI puede ser \"gpt-3.5-turbo\" o \"gpt-4\")\n",
    "\n",
    "**temperature**: controla la aleatoriedad de la respuesta (y la capacidad \"generativa\"), el valor mínimo es 0 (muy baja aleatoriedad y creatividad).\n",
    "\n",
    "**timeout**: el máximo tiempo de espera para obtener la respuesta\n",
    "\n",
    "**max_tokens**: es un número que limita el valor máximo de palabra y puntuación en la respuesta.\n",
    "\n",
    "**api_key**: el api key del usuario\n",
    "\n",
    "No todos los modelos admiten los mismos parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc276cd940e2d89e",
   "metadata": {},
   "source": [
    "Métodos clave del modelo de chat:\n",
    "\n",
    "-**invoke**: El método principal para interactuar con un modelo de chat. Acepta una lista de mensajes como entrada y devuelve una lista de mensajes como salida.\n",
    "\n",
    "-**stream**: Un método que permite transmitir la salida de un modelo de chat a medida que se genera.\n",
    "\n",
    "-**batch**: Un método que permite agrupar varias solicitudes a un modelo de chat para su procesamiento eficiente.\n",
    "\n",
    "-**bind_tools**: Un método que permite vincular una herramienta a un modelo de chat para su uso en el contexto de ejecución del modelo.\n",
    "\n",
    "-**with_structured_output**: Un envoltorio alrededor del método invoke para modelos que admiten natively salida estructurada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb68249f90d9421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:56:11.458246Z",
     "start_time": "2024-11-21T19:56:06.271833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Hola! translates to \"Hello!\" in English.', additional_kwargs={}, response_metadata={'model': 'llama3', 'created_at': '2025-01-15T22:28:53.997854Z', 'done': True, 'done_reason': 'stop', 'total_duration': 21372349500, 'load_duration': 12156594400, 'prompt_eval_count': 20, 'prompt_eval_duration': 3792000000, 'eval_count': 12, 'eval_duration': 5410000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-218cdf09-f535-4f53-88b9-e44a9b17f36d-0', usage_metadata={'input_tokens': 20, 'output_tokens': 12, 'total_tokens': 32})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages= 'Hola, traduce al inglés: hola'\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b84ad75b25a89",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6c4a70a22679655",
   "metadata": {},
   "source": [
    "### 3. Mensajes\n",
    "\n",
    "Un mensaje suele consistir en las siguientes piezas de información:\n",
    "\n",
    "-**Rol**: El rol del mensaje (por ejemplo, \"usuario\", \"asistente\").\n",
    "\n",
    "-**Contenido**: El contenido del mensaje (por ejemplo, texto, datos multimodales).\n",
    "\n",
    "-**Metadatos adicionales**: id, nombre, uso de tokens y otros metadatos específicos del modelo.\n",
    "\n",
    "Rol\n",
    "Los roles se utilizan para distinguir entre diferentes tipos de mensajes en una conversación y ayudar al modelo de chat a entender cómo responder a una secuencia determinada de mensajes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e7721f8ee3daea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:59:40.630742Z",
     "start_time": "2024-11-21T19:59:40.627809Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from english to spanish\"),\n",
    "    HumanMessage(content=\"Hi\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b40ea6efd755e7",
   "metadata": {},
   "source": [
    "Se puede usar un \"parser\" para escribir la respuesta sin metedatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e856039318cc1f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:01:04.397393Z",
     "start_time": "2024-11-21T20:01:03.205263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "result = llm.invoke(messages)\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8226eaac7f614b7",
   "metadata": {},
   "source": [
    "Se pueden juntar el modelo y el parser en una \"chain\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e77666759cdde8df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:01:25.164581Z",
     "start_time": "2024-11-21T20:01:24.358762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8417bbf15244e2f6",
   "metadata": {},
   "source": [
    "**Temperature**\n",
    "\n",
    "Repetimos 5 veces la pregunta \"Escribe un color cualquiera\" y analizamos las respuestas para diferentes valores del parámetro \"temperature\". Para un valor de temperature=0:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a691e0fd7d8349",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:13:24.537977Z",
     "start_time": "2024-11-21T20:13:18.876665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola!\n",
      "\n",
      "El color que te escribo es... **Azul**\n",
      "¡Hola!\n",
      "\n",
      "El color que te escribo es... **Azul**\n",
      "¡Hola!\n",
      "\n",
      "El color que te escribo es... **Azul**\n",
      "¡Hola!\n",
      "\n",
      "El color que te escribo es... **Azul**\n",
      "¡Hola!\n",
      "\n",
      "El color que te escribo es... **Azul**\n"
     ]
    }
   ],
   "source": [
    "messages = 'Hola, escribe un color cualquiera'\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "chain = llm | parser\n",
    "for i in range(5):\n",
    "    print(chain.invoke(messages))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e6899eab795f",
   "metadata": {},
   "source": [
    "Para el valor temperature=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78d574fa7e94211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:14:35.435018Z",
     "start_time": "2024-11-21T20:14:26.332131Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (2759199238.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    messages = 'Hola, escribe un color cualquiera\"\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "messages = 'Hola, escribe un color cualquiera\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1)\n",
    "chain = llm | parser\n",
    "for i in range(5):\n",
    "    print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648613d13e4eb6db",
   "metadata": {},
   "source": [
    "**top-k y top-P**\n",
    "\n",
    "Al igual que la temperatura, los parámetros top-K y top-P también se utilizan para controlar la diversidad de la salida del modelo.\n",
    "\n",
    "Top-K es un número entero positivo que define la cantidad de tokens más probables de los cuales seleccionar el token de salida. Un top-K de 1 selecciona un solo token.\n",
    "\n",
    "Top-P define el umbral de probabilidad que, una vez excedido de forma acumulativa, los tokens dejan de ser seleccionados como candidatos. Un top-P de 0 es equivalente típicamente al top K con k=1, y un top-P de 1 selecciona típicamente todos los tokens en el vocabulario del modelo.\n",
    "\n",
    "Ejecute este ejemplo varias veces, cambie la configuración y observe el cambio en la salida.\n",
    " \n",
    "- top k =64  top_p = 0.95\n",
    "\n",
    "- top k=1 top_p =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520ba039b748d467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:26:17.419229Z",
     "start_time": "2024-11-21T20:25:42.739272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whiskers twitching, ears perked up with excitement, Luna the curious cat slipped out of the cozy house she called home. She had been cooped up indoors for days, watching the same old birds flit about in the backyard, and her insides were buzzing to explore.\n",
      "\n",
      "As night began to fall, casting a warm orange glow over the neighborhood, Luna set off on her adventure. Her tail, like a little metronome, kept perfect time as she padded along the sidewalk. The scent of damp earth and blooming flowers filled her nostrils, and her whiskers quivered with anticipation.\n",
      "\n",
      "Her first stop was the old oak tree in the park. Luna had heard rumors of a hidden tunnel or passageway within its ancient branches. She climbed up the rough bark, using her sharp claws to find holds, until she reached the crook where two great limbs met. There, nestled among the leafy canopy, she discovered a tiny opening just big enough for a curious cat.\n",
      "\n",
      "Luna slipped through the gap and found herself in a narrow tunnel, winding deep into the heart of the tree. The air was thick with mossy scent and the soft hum of nocturnal insects. As she explored this hidden world, she encountered all manner of creatures: fireflies flashing like tiny lanterns, blind white moths fluttering around her ears, and even a family of field mice scurrying about their business.\n",
      "\n",
      "Next, Luna ventured to the nearby creek, where the sound of rushing water beckoned her. She followed the gentle flow until she reached a rocky bend, where fish swam lazily beneath the surface. As she peered into the crystal-clear water, a school of tiny fish darted out from the shadows, playing a game of hide-and-seek among the weeds.\n",
      "\n",
      "The creek's source, a babbling brook hidden among ferns and rhododendrons, was her final destination. Here, Luna discovered a secret glade, where fireflies danced in swirling patterns above the soft grass. In the center of this enchanted clearing stood an ancient willow tree, its branches twisting like a cat's tail.\n",
      "\n",
      "As the first light of dawn crept over the horizon, Luna curled up beneath the willow's wispy fronds, feeling content and full of wonder. She had discovered secrets hidden within the neighborhood, secrets that only revealed themselves after dark. With the rising sun, she made her way back home, where she purred softly to herself, already planning her next nocturnal adventure.\n",
      "\n",
      "From that day on, Luna became known as the resident explorer, always disappearing at dusk to uncover new wonders and return before dawn with tales of her exploits. And though her friends might tease her about being a \"night owl,\" they couldn't help but admire the excitement in her eyes when she spoke of her midnight escapades beneath the stars.\n"
     ]
    }
   ],
   "source": [
    "messages = \"You are a creative writer. Write a short story about a cat who goes on an adventure\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1, top_k=64,\n",
    "        top_p=0.95)\n",
    "chain = llm | parser\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c29fb6084bd0966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:27:29.516198Z",
     "start_time": "2024-11-21T20:26:39.268207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Whiskered Wanderer**\n",
      "\n",
      "In the sleepy town of Willowdale, where sunbeams danced through the windows and dust motes waltzed in the air, a sleek black cat named Midnight prowled the streets. Her eyes gleamed like polished onyx as she padded silently from house to house, searching for adventure.\n",
      "\n",
      "Midnight's owner, an elderly lady named Mrs. Jenkins, had grown fond of her mischievous ways and often left treats and toys scattered about the house. But tonight, Midnight yearned for something more – a taste of freedom, a dash of excitement.\n",
      "\n",
      "As she slipped out into the night air, the world came alive around her. Fireflies twinkled like tiny lanterns, casting a magical glow over the cobblestone streets. The scent of blooming flowers wafted on the breeze, enticing Midnight to explore further.\n",
      "\n",
      "She padded through alleys and side streets, weaving past sleeping dogs and snoring cats. Her ears perked up at every sound – a chirping cricket, a hooting owl, or the distant rumble of thunder. With each step, Midnight felt her whiskers twitching with anticipation.\n",
      "\n",
      "As she wandered deeper into the town, Midnight stumbled upon a hidden path she had never seen before. The air grew thick with the scent of damp earth and moss, and the trees seemed to lean in, as if sharing a secret. Without hesitation, Midnight followed the winding trail, her paws padding softly on the forest floor.\n",
      "\n",
      "The trees grew taller and closer together here, casting dappled shadows across the ground. Midnight's eyes adjusted to the dim light, and she spotted a glint of silver in the distance – a small stream, its surface reflecting the starry sky above.\n",
      "\n",
      "Without hesitation, Midnight plunged into the water, sending ripples through the calm surface. She paddled with her front paws, feeling the cool liquid envelop her fur. As she swam, the world around her dissolved into a kaleidoscope of colors and sounds – the chirping of crickets, the rustling of leaves, and the gentle lapping of water against her ears.\n",
      "\n",
      "For a moment, Midnight forgot about Mrs. Jenkins, the treats, and the comforts of home. She was free, untethered by the constraints of everyday life. The stream became her own personal highway, carrying her to unknown destinations and hidden wonders.\n",
      "\n",
      "As she swam further downstream, Midnight spotted a family of otters playing in the shallows. They welcomed her with open arms – or rather, open paws – and invited her to join their game of chase-the-fish. Midnight laughed, a throaty purr rumbling deep within her chest, as she chased after the slippery creatures.\n",
      "\n",
      "Eventually, the sun began to rise, casting a golden glow over the forest. Midnight reluctantly bid farewell to her new friends and continued downstream, following the stream until it merged with a larger river.\n",
      "\n",
      "As she emerged from the water, shaking off excess droplets, Midnight spotted a majestic castle rising above the trees – its towers reaching for the clouds like giant's fists. The wind whispered secrets in her ear, and Midnight felt an inexplicable pull towards the ancient structure.\n",
      "\n",
      "Without hesitation, she padded up the winding path, her tail twitching with excitement. As she reached the entrance, a pair of stone lions gazed down at her, their eyes gleaming with a knowing intelligence. Midnight pushed open the massive doors, and a warm light spilled out, bathing her in its radiance.\n",
      "\n",
      "Inside, she discovered a labyrinthine library filled with ancient tomes and mysterious artifacts. The air was thick with the scent of parchment and knowledge. Midnight's whiskers twitched as she explored the shelves, uncovering secrets hidden within the pages of forgotten books.\n",
      "\n",
      "As the sun climbed higher in the sky, casting long shadows across the castle walls, Midnight realized it was time to return home. She bid farewell to the library, promising to keep its secrets safe, and began her journey back through the forest.\n",
      "\n",
      "The stream had changed course overnight, but Midnight navigated its twists and turns with ease, guided by the memories of her adventure. As she emerged from the trees, Mrs. Jenkins welcomed her with open arms, a warm smile on her face.\n",
      "\n",
      "\"Midnight, where have you been?\" she asked, scratching behind the cat's ears.\n",
      "\n",
      "Midnight purred contentedly, her eyes gleaming with a secret knowledge. She knew that some adventures were meant to remain hidden, but others – like this one – would stay with her forever, etched in the whispers of her whiskers and the beat of her heart.\n"
     ]
    }
   ],
   "source": [
    "messages = \"You are a creative writer. Write a short story about a cat who goes on an adventure\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1, top_k=1,\n",
    "        top_p=0)\n",
    "chain = llm | parser\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7d135ca719b6130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:30:45.480944Z",
     "start_time": "2024-11-21T20:29:54.503023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Whiskered Wanderer**\n",
      "\n",
      "In the sleepy town of Willowdale, where sunbeams danced through the windows and dust motes waltzed in the air, a sleek black cat named Midnight prowled the streets. Her eyes gleamed like polished onyx as she padded silently from house to house, searching for adventure.\n",
      "\n",
      "Midnight's owner, an elderly lady named Mrs. Jenkins, had grown fond of her mischievous ways and often left treats and toys scattered about the house. But tonight, Midnight yearned for something more – a taste of freedom, a dash of excitement.\n",
      "\n",
      "As she slipped out into the night air, the world came alive around her. Fireflies twinkled like tiny lanterns, casting a magical glow over the cobblestone streets. The scent of blooming flowers wafted on the breeze, enticing Midnight to explore further.\n",
      "\n",
      "She padded through alleys and side streets, weaving past sleeping dogs and snoring cats. Her ears perked up at every sound – a chirping cricket, a hooting owl, or the distant rumble of thunder. With each step, Midnight felt her whiskers twitching with anticipation.\n",
      "\n",
      "As she wandered deeper into the town, Midnight stumbled upon a hidden path she had never seen before. The air grew thick with the scent of damp earth and moss, and the trees seemed to lean in, as if sharing a secret. Without hesitation, Midnight followed the winding trail, her paws padding softly on the forest floor.\n",
      "\n",
      "The trees grew taller and closer together here, casting dappled shadows across the ground. Midnight's eyes adjusted to the dim light, and she spotted a glint of silver in the distance – a small stream, its surface reflecting the starry sky above.\n",
      "\n",
      "Without hesitation, Midnight plunged into the water, sending ripples through the calm surface. She paddled with her front paws, feeling the cool liquid envelop her fur. As she swam, the world around her dissolved into a kaleidoscope of colors and sounds – the chirping of crickets, the rustling of leaves, and the gentle lapping of water against her ears.\n",
      "\n",
      "For a moment, Midnight forgot about Mrs. Jenkins, the treats, and the comforts of home. She was free, untethered by the constraints of everyday life. The stream became her own personal highway, carrying her to unknown destinations and hidden wonders.\n",
      "\n",
      "As she swam further downstream, Midnight spotted a family of otters playing in the shallows. They welcomed her with open arms – or rather, open paws – and invited her to join their game of chase-the-fish. Midnight laughed, a throaty purr rumbling deep within her chest, as she chased after the slippery creatures.\n",
      "\n",
      "Eventually, the sun began to rise, casting a golden glow over the forest. Midnight reluctantly bid farewell to her new friends and continued downstream, following the stream until it merged with a larger river.\n",
      "\n",
      "As she emerged from the water, shaking off excess droplets, Midnight spotted a majestic castle rising above the trees – its towers reaching for the clouds like giant's fists. The wind whispered secrets in her ear, and Midnight felt an inexplicable pull towards the ancient structure.\n",
      "\n",
      "Without hesitation, she padded up the winding path, her tail twitching with excitement. As she reached the entrance, a pair of stone lions gazed down at her, their eyes gleaming with a knowing intelligence. Midnight pushed open the massive doors, and a warm light spilled out, bathing her in its radiance.\n",
      "\n",
      "Inside, she discovered a labyrinthine library filled with ancient tomes and mysterious artifacts. The air was thick with the scent of parchment and knowledge. Midnight's whiskers twitched as she explored the shelves, uncovering secrets hidden within the pages of forgotten books.\n",
      "\n",
      "As the sun climbed higher in the sky, casting long shadows across the castle walls, Midnight realized it was time to return home. She bid farewell to the library, promising to keep its secrets safe, and began her journey back through the forest.\n",
      "\n",
      "The stream had changed course overnight, but Midnight navigated its twists and turns with ease, guided by the memories of her adventure. As she emerged from the trees, Mrs. Jenkins welcomed her with open arms, a warm smile on her face.\n",
      "\n",
      "\"Midnight, where have you been?\" she asked, scratching behind the cat's ears.\n",
      "\n",
      "Midnight purred contentedly, her eyes gleaming with a secret knowledge. She knew that some adventures were meant to remain hidden, but others – like this one – would stay with her forever, etched in the whispers of her whiskers and the beat of her heart.\n"
     ]
    }
   ],
   "source": [
    "messages = \"You are a creative writer. Write a short story about a cat who goes on an adventure\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1, top_k=5,\n",
    "        top_p=0)\n",
    "chain = llm | parser\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feecf481711e508",
   "metadata": {},
   "source": [
    "## 2. Prompt templates\n",
    "\n",
    "Si se quieren hacer preguntas siempre del mismo tipo, dando las mismas instrucciones al sustema, se pueden definir \"prompt templates\", que pueden contener variables, definidas entre {}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8328963faa7b4f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:05:13.245816Z",
     "start_time": "2024-11-21T20:05:13.242267Z"
    }
   },
   "outputs": [],
   "source": [
    "system_template = \"Translate the following into {language}, write only the translated word:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7997d3031ff3b160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:20.103655Z",
     "start_time": "2024-11-21T20:53:20.100003Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "931e2e513973b3a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:21.633014Z",
     "start_time": "2024-11-21T20:53:21.618308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian, write only the translated word:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3782042470db8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:25.711320Z",
     "start_time": "2024-11-21T20:53:25.706511Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fb8794710829214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:32.121166Z",
     "start_time": "2024-11-21T20:53:27.501663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84ee819fef100606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:47.718716Z",
     "start_time": "2024-11-21T20:53:45.841225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "chain.invoke({\"topic\": \"cats\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2854038925b328",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
